# TabNSA: Native sparse attention for efficient tabular data learning

Welcome to the repository for **"TabNSA: Native sparse attention for efficient tabular data learning"**.  

*Paper Acceptance ðŸŽ‰*: This work has been accepted for publication in **Journal of Neurocomputing**.
**Paper**: [TabNSA: Native Sparse Attention for Efficient Tabular Data Learning](https://doi.org/10.1016/j.neucom.2026.132928)

## Overview

TabNSA introduces a native sparse attention mechanism tailored for tabular data. It achieves **superior performance and accuracy** on multiple benchmark datasets compared to existing models.

## Highlights

- Native sparse attention architecture for tabular inputs  
- Significantly improved classification/regression performance  
- Competitive results on standard tabular benchmarks  
- Easily pluggable into PyTorch training pipelines  

## Installation

```bash
git clone https://github.com/yourusername/TabNSA.git
cd TabNSA
pip install -r requirements.txt
